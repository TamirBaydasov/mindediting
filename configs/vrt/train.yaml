system:
  device_target: null
  random_seed: null
  mindspore_seed: null
  numpy_seed: null
  context_mode: "graph_mode"
  is_train_distributed: false
  graph_kernel_flags: null
  enable_graph_kernel: False

model:
  name: "vrt"
  load_path: ""
  spynet_load_path: "/data/LLVT/VRT/ckpt/converted/spynet_sintel_final-3d2a1287.ckpt"
  img_size: # Size of input image. Default: [6, 64, 64].
    - 6
    - 64
    - 64
  window_size: # Window size. Default: (6,8,8).
    - 6
    - 8
    - 8
  depths: # Depths of each Transformer stage.
    - 8
    - 8
    - 8
    - 8
    - 8
    - 8
    - 8
    - 4
    - 4
    - 4
    - 4
    - 4
    - 4
  indep_reconsts: # Layers that extract features of different frames independently.
    - 11
    - 12
  embed_dims: # Number of linear projection output channels.
    - 120
    - 120
    - 120
    - 120
    - 120
    - 120
    - 120
    - 180
    - 180
    - 180
    - 180
    - 180
    - 180
  num_heads: # Number of attention head of each stage.
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
    - 6
  pa_frames: 2 # Number of warpped frames. Default: 2.
  deformable_groups: 12 # Number of deformable groups. Default: 16.
  nonblind_denoising: false # If True, conduct experiments on non-blind denoising. Default: False.

# Dataset options
dataset:
  dataset_name: "reds"
  input_path: "/data/LLVT/TTVSR/data/REDS/"
  train_annotation: 'REDS266.txt'
  test_annotation: 'REDS4.txt'
  gt_subdir: 'trainval_sharp_HR/'
  lr_subdir: 'trainval_sharp_bicubic/X4'
  batch_size: 1 # x 8 devices = 8 as total batch size
  gt_size: 256 # Cropped patched size for gt patches
  lr_type: "bicubic"
  scale: 4
  n_channels: 3
  dataset_sink_mode: False
  num_frames: 6
  num_samples: null
  eval_batch_size: 1
  num_parallel_workers: 8
# Common training options
loss:
  name: "CharbonnierLoss"
  weight: 1.0
  amp_level: "O0"
  loss_scale: 1000.0 # for ['O2', 'O3', 'auto']

# Training
train:
  cast_net: "float16"
  cast_loss: "float32"
  is_use_dynamic_loss_scale: True
  val_monitor: False
  eval_network: "cast_fp32"

# Optimizer options
optimizer:
  name: "Adam"
  learning_rate: 2.0e-4 # should not be used
  weight_decay: 0.0
  beta1: 0.9
  beta2: 0.99

# Scheduler options
scheduler:
  name: "cosine_annealing"
  base_lr: 2.0e-4
  min_lr: 1.0e-7
  warmup_epochs: 0
  warmup_factor: 0.0
  warmup_base_lr: 2.0e-4

extra_scheduler:
  name: "warmup_cosine_annealing"
  lr_mul: 0.125
  warmup_epochs: 1 # freeze epochs ~5000 iter for vimeo
  warmup_factor: 0.0
  warmup_base_lr: 0.0 # freeze
  param_prefixes: ["spynet", "deform"]

# Metric options
metric:
  PSNR:
    reduction: 'avg'
    crop_border: 0
    input_order: 'CHW'
    convert_to: null
  SSIM:
    reduction: 'avg'
    crop_border: 0
    input_order: 'CHW'
    convert_to: null

train_params:
  epoch_size: 9000 # ~300000 iter for reds266
  need_val: True
  keep_checkpoint_max: 60
  save_epoch_frq: 1
  eval_frequency: 10
  print_frequency: 10
  ckpt_save_dir: "./ckpt/vrt"
  profile:
    start: 2
    stop: 10
    output_path: profile
    by_epoch: False
    exit_after: True
    add_datetime_suffix: True

# Preprocessing pipeline and augmentations for training phase
train_pipeline: null

# Preprocessing pipeline and augmentations for evaluation phase
test_pipeline: null
