# ==============================================================================
system:
  random_seed: null
  mindspore_seed: null
  numpy_seed: null
  context_mode: "graph_mode"
  graph_kernel_flags: null
  enable_graph_kernel: False

model:
  name: "ifr_plus"
  load_path: null
  encoder_load_path: "/data/LLVT/IFR_Plus/ckpt/converted/convnextv2-femto.ckpt"
  input_channels: 3
  decoder_channels: [ 64, 96, 144, 192 ]
  side_channels: 64
  refiner_channels: [ 24, 48, 96 ]
  to_float16: False
  flow_scale_factor: 1.0
  refiner_scale_factor: 1.0

validator:
  name: "tiling"
  temporal_overlap: 0
  spatial_overlap: 0
  temporal_size: 0
  spatial_size: [0, 0]  # h,w
  scale: 1
  input_tensor_type: "mindspore"

dataset:
  dataset_name: "vimeo_triplet"
  input_path: "/data/LLVT/IFR_Plus/data/vimeo_triplet_reduced"
  train_annotation: 'tri_trainlist.txt'
  test_annotation: 'tri_testlist.txt'
  batch_size: 6
  num_frames: null
  dataset_sink_mode: False
  num_samples: null
  eval_batch_size: 1
  num_parallel_workers: 4

# Common training options
loss:
  name: "IFRPlusLoss"
  amp_level: 'O0'
  pixel_weight: 1.0
  freq_weight: 1.0
  iqa_weight: 0.1
  flow_weight: 0.00178
  lpips_pretrained: "/data/LLVT/IFR_Plus/ckpt/converted/LPIPS.ckpt"
  vgg_pretrained: "/data/LLVT/IFR_Plus/ckpt/converted/vgg16-397923af.ckpt"

# Optimizer options
optimizer:
  name: "AdamW"
  weight_decay: 1.0e-2
  beta1: 0.9
  beta2: 0.999
  eps: 1.0e-8
  learning_rate: 1.0e-4

# Scheduler options
scheduler:
  name: "cosine_annealing"
  base_lr: 1.0e-4
  min_lr: 1.0e-6
  warmup_epochs: 0
  warmup_factor: 0.0
  warmup_base_lr: 2.0e-4 # freeze

# Metric options (use RGB channel)
metric:
  PSNR:
    reduction: 'avg'
    crop_border: 0
    input_order: 'CHW'
    convert_to: null
  SSIM:
    reduction: 'avg'
    crop_border: 0
    input_order: 'CHW'
    convert_to: null

# Training
train:
  cast_net: "base"
  cast_loss: "base"
  is_use_dynamic_loss_scale: True
  val_monitor: False
  eval_network: "cast_fp32"

train_params:
  epoch_size: 100
  need_val: False
  keep_checkpoint_max: 10
  save_epoch_frq: 1
  eval_frequency: 1
  print_frequency: 100
  ckpt_save_dir: "./ckpt/ifr_plus"
  profile:
    start: 2
    stop: 10
    output_path: profile
    by_epoch: False
    exit_after: True
    add_datetime_suffix: True

# Preprocessing pipeline and augmentations for training phase
train_pipeline:
  name: "ifr_plus"
  pipeline:
    - RandomResize:
        keys: [ 'inputs', 'target', 'flow' ]
        modes: [ 'img', 'img', 'flow' ]
        scale: 2.0
        resize_ratio: 0.1
    - RandomCrop:
        keys: [ 'inputs', 'target', 'flow' ]
        crop_size: [ 224, 224 ]
    - RandomFlip:
        keys: [ 'inputs', 'target', 'flow' ]
        modes: [ 'img', 'img', 'flow' ]
        direction: 'vertical'
        flip_ratio: 0.3
    - RandomFlip:
        keys: [ 'inputs', 'target', 'flow' ]
        modes: [ 'img', 'img', 'flow' ]
        direction: 'horizontal'
        flip_ratio: 0.5
    - RandomTransposeHW:
        keys: [ 'inputs', 'target', 'flow' ]
        modes: [ 'img', 'img', 'flow' ]
        transpose_ratio: 0.05
    - RandomChannelReverse:
        keys: [ 'inputs', 'target' ]
        reverse_ratio: 0.5
    - RandomTemporalReverse:
        keys: [ 'inputs', 'flow' ]
        reverse_ratio: 0.5
    - RescaleToZeroOne:
        keys: [ 'inputs', 'target' ]
    - Collect:
        keys: [ 'inputs', 'target', 'flow' ]

# Preprocessing pipeline and augmentations for evaluation phase
test_pipeline:
  name: "ifr_plus"
  pipeline:
    - RescaleToZeroOne:
        keys: [ 'inputs', 'target' ]
    - Collect:
        keys: [ 'inputs', 'target' ]
